# =============================================================================
# UNIFIED DEVELOPMENT ENVIRONMENT
# Single container running Backend + AI Service + Frontend + Database
# Microservice architecture for development with hot reload capabilities
# =============================================================================

version: "3.8"

services:
  # Database service (PostgreSQL with pgvector)
  db:
    image: pgvector/pgvector:0.8.0-pg17
    container_name: echo_notes_db_unified
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: echo_note_rag
    volumes:
      - pgdata_unified:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - echo_network_unified
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d echo_note_rag"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Unified application container
  echo_notes_app:
    build:
      context: .
      dockerfile: Dockerfile.unified
    container_name: echo_notes_unified_app
    depends_on:
      db:
        condition: service_healthy
    environment:
      # Database Configuration
      DATABASE_URL: postgresql+asyncpg://postgres:postgres@db:5432/echo_note_rag

      # Backend Configuration
      JWT_SECRET_KEY: ${JWT_SECRET_KEY:-dev-secret-key-change-in-production}
      CORS_ORIGINS: http://localhost,http://localhost:3000,http://localhost:80
      TRUSTED_HOSTS: localhost,127.0.0.1,echo_notes_app

      # AI Service Configuration
      AI_SERVICE_URL: http://localhost:8002
      AI_SERVICE_TIMEOUT: 300

      # AI Service Internal Configuration
      AI_SERVICE_HOST: 0.0.0.0
      AI_SERVICE_PORT: 8002
      AI_SERVICE_BACKEND_SERVICE_URL: http://localhost:8001

      # OpenAI Configuration
      AI_SERVICE_OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      AI_SERVICE_OPENAI_MODEL: ${OPENAI_MODEL:-gpt-4o-mini}
      AI_SERVICE_OPENAI_EMBEDDING_MODEL: ${OPENAI_EMBEDDING_MODEL:-text-embedding-3-small}
      AI_SERVICE_TEMPERATURE: 0.1

      # HuggingFace Configuration
      AI_SERVICE_HUGGINGFACE_API_TOKEN: ${HUGGINGFACEHUB_API_TOKEN:-}
      AI_SERVICE_HUGGINGFACE_MODEL_ID: ${HUGGINGFACE_MODEL_ID:-aaditya/Llama3-OpenBioLLM-70B}

      # NER Configuration
      AI_SERVICE_NER_MODEL_NAME: ${NER_MODEL_NAME:-d4data/biomedical-ner-all}

      # Model Caching Configuration
      AI_SERVICE_TRANSFORMERS_CACHE: /app/.cache/huggingface
      AI_SERVICE_HF_HOME: /app/.cache/huggingface
      AI_SERVICE_TORCH_HOME: /app/.cache/torch

      # Performance Configuration
      AI_SERVICE_MAX_CONCURRENT_REQUESTS: 10
      AI_SERVICE_REQUEST_TIMEOUT: 300
      AI_SERVICE_LOG_LEVEL: INFO

      # AWS S3 Configuration (optional for development)
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-}
      AWS_REGION: ${AWS_REGION:-ap-south-1}
      S3_BUCKET_NAME: ${S3_BUCKET_NAME:-bucket-of-echo}
      S3_ENDPOINT_URL: ${S3_ENDPOINT_URL:-}

      # Frontend Configuration
      NODE_ENV: development
      NEXT_PUBLIC_API_URL: http://localhost/api
      NEXT_PUBLIC_APP_URL: http://localhost

    ports:
      # Main access port (nginx proxy)
      - "80:80"

      # Direct service access for development/debugging
      - "3000:3000" # Frontend (Next.js)
      - "8001:8001" # Backend (FastAPI)
      - "8002:8002" # AI Service (FastAPI)

    volumes:
      # Model cache persistence
      - ai_cache_unified:/app/.cache

      # Development hot reload (optional - uncomment for development)
      # - ./backend:/app/backend
      # - ./ai_service:/app/ai_service
      # - ./frontend:/app/frontend

    networks:
      - echo_network_unified
    restart: unless-stopped
    healthcheck:
      test: |
        curl -f http://localhost:80/health &&
        curl -f http://localhost:80/ai-health &&
        curl -f http://localhost:3000
      interval: 30s
      timeout: 30s
      start_period: 180s # Allow time for all services to start
      retries: 3

volumes:
  pgdata_unified:
    driver: local
  ai_cache_unified:
    driver: local

networks:
  echo_network_unified:
    driver: bridge
